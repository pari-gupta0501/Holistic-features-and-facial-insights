{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b18ead-eca8-4aae-bbad-507bc13ed237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and compiled model from C:\\Users\\abhid\\Downloads\\gender_model.h5\n",
      "Successfully loaded and compiled model from C:\\Users\\abhid\\Downloads\\age_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and compiled model from C:\\Users\\abhid\\Downloads\\face_shape_model.h5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c921dcb6764d0aa3327964c0f86f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='image/*', description='Upload'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing Necessary Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load model with error handling and compile with placeholder metrics\n",
    "def load_and_compile_model(model_path):\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(f\"Successfully loaded and compiled model from {model_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from {model_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Loading Pretrained Models\n",
    "gender_model = load_and_compile_model(r\"C:\\Users\\abhid\\Downloads\\gender_model.h5\")\n",
    "age_model = load_and_compile_model(r\"C:\\Users\\abhid\\Downloads\\age_model.h5\")\n",
    "face_shape_model = load_and_compile_model(r\"C:\\Users\\abhid\\Downloads\\face_shape_model.h5\")\n",
    "\n",
    "# Define the function for face detection and alignment\n",
    "def detect_and_align_face(image_path):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    # Assuming only one face per image for simplicity\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = img[y:y+h, x:x+w]\n",
    "        aligned_face = cv2.resize(face, (64, 64))\n",
    "        return aligned_face\n",
    "    return None\n",
    "\n",
    "# Define function for gender prediction\n",
    "def predict_gender(aligned_face):\n",
    "    img_array = img_to_array(aligned_face) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    gender_pred = gender_model.predict(img_array)\n",
    "    gender = 'male' if np.argmax(gender_pred) == 1 else 'female'\n",
    "    return gender\n",
    "\n",
    "# Define function for age prediction\n",
    "def predict_age(aligned_face):\n",
    "    img_array = img_to_array(aligned_face) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    age_pred = age_model.predict(img_array)\n",
    "    age = np.argmax(age_pred)\n",
    "    return age\n",
    "\n",
    "# Define function for face shape prediction\n",
    "def predict_face_shape(aligned_face):\n",
    "    img_array = img_to_array(aligned_face) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    face_shape_pred = face_shape_model.predict(img_array)\n",
    "    face_shape_classes = ['oval', 'round', 'square', 'heart', 'diamond']\n",
    "    face_shape = face_shape_classes[np.argmax(face_shape_pred)]\n",
    "    return face_shape\n",
    "\n",
    "# Hairstyle recommendation based on face shape\n",
    "def recommend_hairstyle(face_shape):\n",
    "    recommendations = {\n",
    "        'oval': 'Oval faces can try various hairstyles like long waves or sleek bobs.',\n",
    "        'round': 'Round faces benefit from hairstyles with volume on top, like pompadours.',\n",
    "        'square': 'Square faces look great with soft, layered styles or side-swept bangs.',\n",
    "        'heart': 'Heart faces can try chin-length bobs or shoulder-length waves.',\n",
    "        'diamond': 'Diamond faces look good with hairstyles that add width at the forehead, like side parts.'\n",
    "    }\n",
    "    return recommendations.get(face_shape, \"No recommendation available\")\n",
    "\n",
    "# User Interface for Input and Display of Results\n",
    "from IPython.display import display, Image as IPImage\n",
    "from ipywidgets import widgets, VBox, HBox\n",
    "\n",
    "def on_upload_change(change):\n",
    "    for name, file_info in change['new'].items():\n",
    "        # Save the uploaded file to disk\n",
    "        with open(name, 'wb') as f:\n",
    "            f.write(file_info['content'])\n",
    "        \n",
    "        # Display the uploaded image\n",
    "        display(IPImage(name))\n",
    "        \n",
    "        # Process the image\n",
    "        aligned_face = detect_and_align_face(name)\n",
    "        if aligned_face is not None:\n",
    "            gender = predict_gender(aligned_face)\n",
    "            age = predict_age(aligned_face)\n",
    "            face_shape = predict_face_shape(aligned_face)\n",
    "            hairstyle_recommendation = recommend_hairstyle(face_shape)\n",
    "            \n",
    "            # Display the results\n",
    "            results.value = f\"\"\"\n",
    "            **Gender:** {gender}\n",
    "            **Age:** {age}\n",
    "            **Face Shape:** {face_shape}\n",
    "            **Hairstyle Recommendation:** {hairstyle_recommendation}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            results.value = \"No face detected. Please upload a clearer image.\"\n",
    "\n",
    "upload_button = widgets.FileUpload(accept='image/*', multiple=False)\n",
    "upload_button.observe(on_upload_change, names='value')\n",
    "\n",
    "results = widgets.HTML()\n",
    "\n",
    "display(VBox([upload_button, results]))\n",
    "\n",
    "# End of the Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee591047-8f12-46b9-aadc-e93e7b818512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
